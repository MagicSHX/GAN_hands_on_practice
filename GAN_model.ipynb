{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mnist import MNIST\n",
    "import torch\n",
    "from torch import nn\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data_file_path = \"Data/fake_data_generated.csv\"\n",
    "Discriminator_model_file_path = \"Model/Discriminator_model.pt\"\n",
    "GAN_model_file_path = \"Model/GAN_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_array_generation(array_size, no_of_array):\n",
    "    array_generated = np.random.rand(no_of_array, array_size)\n",
    "    return array_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('Data')\n",
    "#images, labels = mndata.load_training()\n",
    "images, labels = mndata.load_testing()\n",
    "\n",
    "#print(labels)\n",
    "len(images[0])\n",
    "\n",
    "real_input_tensor = torch.Tensor(images)\n",
    "real_output_tensor = torch.Tensor([1 for i in range(real_input_tensor.size(0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = 1\n",
    "if fake_data == 0:\n",
    "    array_generated = random_array_generation(100, 10000)\n",
    "    np.savetxt(fake_data_file_path, array_generated, delimiter=\",\")\n",
    "else:\n",
    "    array_generated = pd.read_csv(fake_data_file_path, header = None)\n",
    "\n",
    "fake_input_tensor = torch.Tensor(array_generated.values)\n",
    "fake_output_tensor = torch.Tensor([0 for i in range(fake_input_tensor.size(0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8113, 0.8830, 0.1161, 0.9041, 0.8295, 0.5640, 0.9597, 0.6732, 0.0773,\n",
       "        0.1733, 0.2507, 0.6257, 0.9794, 0.8131, 0.3409, 0.2037, 0.1561, 0.0355,\n",
       "        0.5426, 0.2767, 0.3555, 0.7762, 0.0477, 0.5486, 0.8409, 0.4584, 0.2002,\n",
       "        0.7612, 0.9665, 0.6159, 0.1208, 0.2811, 0.6921, 0.0898, 0.7824, 0.8461,\n",
       "        0.4351, 0.9992, 0.0376, 0.0379, 0.6627, 0.2711, 0.9265, 0.7212, 0.3231,\n",
       "        0.1601, 0.4817, 0.1492, 0.5890, 0.4626, 0.2383, 0.6736, 0.7089, 0.3591,\n",
       "        0.5928, 0.4461, 0.3668, 0.2426, 0.3939, 0.3521, 0.2196, 0.7634, 0.2150,\n",
       "        0.8353, 0.6717, 0.5992, 0.1051, 0.9078, 0.4213, 0.4814, 0.1232, 0.9127,\n",
       "        0.4303, 0.7778, 0.7342, 0.6365, 0.2763, 0.2299, 0.8172, 0.6221, 0.7781,\n",
       "        0.4370, 0.7914, 0.7638, 0.9722, 0.0175, 0.2349, 0.3645, 0.2698, 0.4705,\n",
       "        0.3708, 0.1050, 0.1174, 0.5793, 0.8773, 0.4560, 0.3683, 0.7286, 0.3473,\n",
       "        0.1747])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_input_tensor[0]\n",
    "#real_output_tensor\n",
    "fake_input_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_input_tensor.size(0)\n",
    "fake_output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(GAN_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 512)\n",
    "        self.fc3 = nn.Linear(512, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator_Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Discriminator_Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8113, 0.8830, 0.1161, 0.9041, 0.8295, 0.5640, 0.9597, 0.6732, 0.0773,\n",
      "        0.1733, 0.2507, 0.6257, 0.9794, 0.8131, 0.3409, 0.2037, 0.1561, 0.0355,\n",
      "        0.5426, 0.2767, 0.3555, 0.7762, 0.0477, 0.5486, 0.8409, 0.4584, 0.2002,\n",
      "        0.7612, 0.9665, 0.6159, 0.1208, 0.2811, 0.6921, 0.0898, 0.7824, 0.8461,\n",
      "        0.4351, 0.9992, 0.0376, 0.0379, 0.6627, 0.2711, 0.9265, 0.7212, 0.3231,\n",
      "        0.1601, 0.4817, 0.1492, 0.5890, 0.4626, 0.2383, 0.6736, 0.7089, 0.3591,\n",
      "        0.5928, 0.4461, 0.3668, 0.2426, 0.3939, 0.3521, 0.2196, 0.7634, 0.2150,\n",
      "        0.8353, 0.6717, 0.5992, 0.1051, 0.9078, 0.4213, 0.4814, 0.1232, 0.9127,\n",
      "        0.4303, 0.7778, 0.7342, 0.6365, 0.2763, 0.2299, 0.8172, 0.6221, 0.7781,\n",
      "        0.4370, 0.7914, 0.7638, 0.9722, 0.0175, 0.2349, 0.3645, 0.2698, 0.4705,\n",
      "        0.3708, 0.1050, 0.1174, 0.5793, 0.8773, 0.4560, 0.3683, 0.7286, 0.3473,\n",
      "        0.1747])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "learning_rate_Discriminator = 0.08\n",
    "epoch_size_Discriminator = 5\n",
    "steps_for_printing_out_loss_Discriminator = 5\n",
    "\n",
    "Discriminator_Model_WIP = Discriminator_Model(input_size = 784, output_size = 1)\n",
    "\n",
    "Discriminator_Model_WIP.to(device)\n",
    "loss_functioin_Discriminator = nn.MSELoss()\n",
    "optimizer_Discriminator = optim.SGD(Discriminator_Model_WIP.parameters(), lr = learning_rate_Discriminator)\n",
    "\n",
    "input_real = (real_input_tensor/ 256).cuda()\n",
    "target_real = real_output_tensor.cuda()\n",
    "#input_fake = fake_input_tensor\n",
    "target_fake = fake_output_tensor.cuda()\n",
    "print(fake_input_tensor[0])\n",
    "def Discriminator_training_model():\n",
    "    input_fake = GAN_Model_WIP(fake_input_tensor.cuda())\n",
    "    #print(input_fake[0])\n",
    "    for i in range(1, epoch_size_Discriminator + 1):\n",
    "        optimizer_Discriminator.zero_grad()\n",
    "        output_real = Discriminator_Model_WIP(input_real.cuda())\n",
    "        loss_real = loss_functioin_Discriminator(output_real, target_real.reshape(output_real.size(0), output_real.size(1)))\n",
    "        loss_real.backward()\n",
    "        #loss_real.backward()\n",
    "        output_fake = Discriminator_Model_WIP(input_fake.cuda())\n",
    "        #print(output_real)\n",
    "        loss_fake = loss_functioin_Discriminator(output_fake, target_fake.reshape(output_fake.size(0), output_fake.size(1)))\n",
    "        loss_fake.backward(retain_graph=True)\n",
    "        #loss_fake.backward()\n",
    "        optimizer_Discriminator.step()\n",
    "        loss_Discriminator = loss_real + loss_fake\n",
    "        print(loss_real.cpu().detach().numpy())\n",
    "        print(loss_fake.cpu().detach().numpy())\n",
    "        \n",
    "        if i % (steps_for_printing_out_loss_Discriminator) == 0:\n",
    "            print('Loss (epoch: ' + str(i) + '): ' + str(loss_Discriminator.cpu().detach().numpy()))\n",
    "    torch.save({'state_dict': Discriminator_Model_WIP.state_dict(),'optimizer': optimizer_Discriminator.state_dict()}, Discriminator_model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "learning_rate_GAN = 0.08\n",
    "epoch_size_GAN = 5\n",
    "steps_for_printing_out_loss_GAN = 1\n",
    "\n",
    "GAN_Model_WIP = GAN_Model(input_size = 100, output_size = 784)\n",
    "\n",
    "GAN_Model_WIP.to(device)\n",
    "loss_functioin_GAN = nn.MSELoss()\n",
    "optimizer_GAN = optim.SGD(GAN_Model_WIP.parameters(), lr = learning_rate_GAN)\n",
    "input_GAN = fake_input_tensor.cuda()\n",
    "target_GAN = torch.Tensor([1 for i in range(input_GAN.size(0))]).cuda()\n",
    "def GAN_training_model():\n",
    "    for i in range(1, epoch_size_GAN + 1):\n",
    "        optimizer_GAN.zero_grad()\n",
    "        output_GAN = Discriminator_Model_WIP(GAN_Model_WIP(input_GAN.cuda()))\n",
    "        loss_GAN = loss_functioin_GAN(output_GAN, target_GAN.reshape(output_GAN.size(0), output_GAN.size(1)))\n",
    "        loss_GAN.backward()\n",
    "        if i % (steps_for_printing_out_loss_GAN) == 0:\n",
    "            print('Loss (epoch: ' + str(i) + '): ' + str(loss_GAN.cpu().detach().numpy()))\n",
    "        optimizer_GAN.step()\n",
    "\n",
    "    torch.save({'state_dict': GAN_Model_WIP.state_dict(),'optimizer': optimizer_GAN.state_dict()}, GAN_model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9902027\n",
      "0.0\n",
      "0.7409174\n",
      "0.002593733\n",
      "0.20029025\n",
      "0.054878928\n",
      "0.049930707\n",
      "0.088123284\n",
      "0.047202766\n",
      "0.06841305\n",
      "Loss (epoch: 5): 0.115615815\n",
      "Loss (epoch: 1): 0.60145146\n",
      "Loss (epoch: 2): 0.5862785\n",
      "Loss (epoch: 3): 0.56843805\n",
      "Loss (epoch: 4): 0.54812413\n",
      "Loss (epoch: 5): 0.5254685\n",
      "0.049205784\n",
      "0.08566376\n",
      "0.05754602\n",
      "0.056875207\n",
      "0.054006524\n",
      "0.045901172\n",
      "0.056742407\n",
      "0.03276641\n",
      "0.056095604\n",
      "0.025956593\n",
      "Loss (epoch: 5): 0.0820522\n",
      "Loss (epoch: 1): 0.741037\n",
      "Loss (epoch: 2): 0.70395863\n",
      "Loss (epoch: 3): 0.6567504\n",
      "Loss (epoch: 4): 0.6005244\n",
      "Loss (epoch: 5): 0.53608316\n",
      "0.057221692\n",
      "0.10220908\n",
      "0.08958082\n",
      "0.042041127\n",
      "0.0608952\n",
      "0.050438225\n",
      "0.078901365\n",
      "0.02011194\n",
      "0.06315894\n",
      "0.026789105\n",
      "Loss (epoch: 5): 0.08994804\n",
      "Loss (epoch: 1): 0.8217771\n",
      "Loss (epoch: 2): 0.7447291\n",
      "Loss (epoch: 3): 0.6453071\n",
      "Loss (epoch: 4): 0.532571\n",
      "Loss (epoch: 5): 0.41507742\n",
      "0.07623079\n",
      "0.20488466\n",
      "0.20652072\n",
      "0.014678315\n",
      "0.08044458\n",
      "0.10904746\n",
      "0.2621125\n",
      "0.0\n",
      "0.11538957\n",
      "0.056194153\n",
      "Loss (epoch: 5): 0.17158373\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.256557\n",
      "0.0\n",
      "0.09291502\n",
      "0.019697974\n",
      "0.14079295\n",
      "0.0\n",
      "0.08099627\n",
      "0.009389833\n",
      "0.10171259\n",
      "0.0\n",
      "Loss (epoch: 5): 0.10171259\n",
      "Loss (epoch: 1): 0.858266\n",
      "Loss (epoch: 2): 0.78521824\n",
      "Loss (epoch: 3): 0.6501603\n",
      "Loss (epoch: 4): 0.47400323\n",
      "Loss (epoch: 5): 0.3144997\n",
      "0.06903231\n",
      "0.319166\n",
      "0.5810122\n",
      "0.0\n",
      "0.050822183\n",
      "0.009678022\n",
      "0.048568163\n",
      "0.0025341571\n",
      "0.04637926\n",
      "0.0017831727\n",
      "Loss (epoch: 5): 0.048162434\n",
      "Loss (epoch: 1): 0.9402866\n",
      "Loss (epoch: 2): 0.8999987\n",
      "Loss (epoch: 3): 0.80696064\n",
      "Loss (epoch: 4): 0.6545221\n",
      "Loss (epoch: 5): 0.501417\n",
      "0.045283217\n",
      "0.16305764\n",
      "0.21641882\n",
      "0.0\n",
      "0.06573896\n",
      "0.014250414\n",
      "0.089850575\n",
      "0.0\n",
      "0.05589268\n",
      "0.0028076775\n",
      "Loss (epoch: 5): 0.058700357\n",
      "Loss (epoch: 1): 0.9992009\n",
      "Loss (epoch: 2): 0.9963127\n",
      "Loss (epoch: 3): 0.97587615\n",
      "Loss (epoch: 4): 0.94379234\n",
      "Loss (epoch: 5): 0.9095294\n",
      "0.056079295\n",
      "0.0046059564\n",
      "0.043032292\n",
      "0.0074910466\n",
      "0.04711529\n",
      "0.000827861\n",
      "0.04113697\n",
      "0.0023315677\n",
      "0.040779393\n",
      "0.00043101257\n",
      "Loss (epoch: 5): 0.041210406\n",
      "Loss (epoch: 1): 0.931069\n",
      "Loss (epoch: 2): 0.89382994\n",
      "Loss (epoch: 3): 0.8199449\n",
      "Loss (epoch: 4): 0.68553853\n",
      "Loss (epoch: 5): 0.5392872\n",
      "0.037589695\n",
      "0.13170943\n",
      "0.15389821\n",
      "0.0\n",
      "0.06871985\n",
      "0.0038751524\n",
      "0.07411309\n",
      "0.0\n",
      "0.04809628\n",
      "0.0018607778\n",
      "Loss (epoch: 5): 0.04995706\n",
      "Loss (epoch: 1): 0.9878455\n",
      "Loss (epoch: 2): 0.9639201\n",
      "Loss (epoch: 3): 0.9405939\n",
      "Loss (epoch: 4): 0.91474295\n",
      "Loss (epoch: 5): 0.8872237\n",
      "0.046565484\n",
      "0.0052785217\n",
      "0.036815133\n",
      "0.0059258956\n",
      "0.038375363\n",
      "0.0013677691\n",
      "0.034625165\n",
      "0.0020020783\n",
      "0.034219723\n",
      "0.000658474\n",
      "Loss (epoch: 5): 0.034878198\n",
      "Loss (epoch: 1): 0.93654776\n",
      "Loss (epoch: 2): 0.9135732\n",
      "Loss (epoch: 3): 0.8743661\n",
      "Loss (epoch: 4): 0.79175574\n",
      "Loss (epoch: 5): 0.67555803\n",
      "0.03219293\n",
      "0.066524096\n",
      "0.0626677\n",
      "4.147441e-09\n",
      "0.046853498\n",
      "0.002678789\n",
      "0.048642527\n",
      "3.4267728e-07\n",
      "0.039269146\n",
      "0.0013391429\n",
      "Loss (epoch: 5): 0.040608287\n",
      "Loss (epoch: 1): 0.98938984\n",
      "Loss (epoch: 2): 0.970153\n",
      "Loss (epoch: 3): 0.94695044\n",
      "Loss (epoch: 4): 0.9180277\n",
      "Loss (epoch: 5): 0.8719128\n",
      "0.038550597\n",
      "0.011922841\n",
      "0.031693075\n",
      "0.0029954822\n",
      "0.032146893\n",
      "0.00067453744\n",
      "0.030656375\n",
      "0.0008554586\n",
      "0.030162822\n",
      "0.00030430686\n",
      "Loss (epoch: 5): 0.03046713\n",
      "Loss (epoch: 1): 0.9556015\n",
      "Loss (epoch: 2): 0.9277033\n",
      "Loss (epoch: 3): 0.8557027\n",
      "Loss (epoch: 4): 0.71536714\n",
      "Loss (epoch: 5): 0.58970827\n",
      "0.0289532\n",
      "0.09843409\n",
      "0.07548896\n",
      "0.0\n",
      "0.055479717\n",
      "1.7099172e-10\n",
      "0.055662073\n",
      "0.0\n",
      "0.042127505\n",
      "4.9930502e-05\n",
      "Loss (epoch: 5): 0.042177435\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.040048324\n",
      "0.0\n",
      "0.03332044\n",
      "0.00025166216\n",
      "0.03165735\n",
      "1.1980406e-06\n",
      "0.028312473\n",
      "0.00037623243\n",
      "0.02722586\n",
      "3.5038567e-05\n",
      "Loss (epoch: 5): 0.027260898\n",
      "Loss (epoch: 1): 0.9630574\n",
      "Loss (epoch: 2): 0.94163436\n",
      "Loss (epoch: 3): 0.9129959\n",
      "Loss (epoch: 4): 0.86660117\n",
      "Loss (epoch: 5): 0.7893299\n",
      "0.02534609\n",
      "0.025776833\n",
      "0.03470431\n",
      "9.2706006e-07\n",
      "0.029715564\n",
      "0.000890274\n",
      "0.02925183\n",
      "2.0421166e-06\n",
      "0.02629162\n",
      "0.0004707469\n",
      "Loss (epoch: 5): 0.026762366\n",
      "Loss (epoch: 1): 0.9943121\n",
      "Loss (epoch: 2): 0.975241\n",
      "Loss (epoch: 3): 0.9430195\n",
      "Loss (epoch: 4): 0.8823974\n",
      "Loss (epoch: 5): 0.77352476\n",
      "0.025553146\n",
      "0.037984252\n",
      "0.030442806\n",
      "2.2676184e-06\n",
      "0.027868085\n",
      "0.00075539184\n",
      "0.027856583\n",
      "7.9807506e-07\n",
      "0.025743462\n",
      "0.0004253784\n",
      "Loss (epoch: 5): 0.02616884\n",
      "Loss (epoch: 1): 0.99758416\n",
      "Loss (epoch: 2): 0.981358\n",
      "Loss (epoch: 3): 0.9305081\n",
      "Loss (epoch: 4): 0.8551717\n",
      "Loss (epoch: 5): 0.7468909\n",
      "0.025309414\n",
      "0.041745905\n",
      "0.03068135\n",
      "5.2897776e-06\n",
      "0.028411401\n",
      "0.0009939622\n",
      "0.029168999\n",
      "5.4057128e-09\n",
      "0.02694054\n",
      "0.00047559445\n",
      "Loss (epoch: 5): 0.027416134\n",
      "Loss (epoch: 1): 0.99997526\n",
      "Loss (epoch: 2): 0.9999693\n",
      "Loss (epoch: 3): 0.9999601\n",
      "Loss (epoch: 4): 0.9999445\n",
      "Loss (epoch: 5): 0.9999173\n",
      "0.026968017\n",
      "1.6168312e-07\n",
      "0.024959084\n",
      "0.0004575709\n",
      "0.024848027\n",
      "4.0144147e-07\n",
      "0.023119796\n",
      "0.00035088637\n",
      "0.022816496\n",
      "1.7860904e-06\n",
      "Loss (epoch: 5): 0.022818282\n",
      "Loss (epoch: 1): 0.9663781\n",
      "Loss (epoch: 2): 0.9033338\n",
      "Loss (epoch: 3): 0.78993595\n",
      "Loss (epoch: 4): 0.6452534\n",
      "Loss (epoch: 5): 0.4867751\n",
      "0.021387981\n",
      "0.1691821\n",
      "0.14477345\n",
      "0.0\n",
      "0.07414415\n",
      "0.0\n",
      "0.078695066\n",
      "0.0\n",
      "0.04204267\n",
      "0.0\n",
      "Loss (epoch: 5): 0.04204267\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.03820094\n",
      "0.0\n",
      "0.02786189\n",
      "0.0\n",
      "0.02508398\n",
      "0.0\n",
      "0.021848721\n",
      "4.1891726e-09\n",
      "0.020375414\n",
      "0.0\n",
      "Loss (epoch: 5): 0.020375414\n",
      "Loss (epoch: 1): 0.99973434\n",
      "Loss (epoch: 2): 0.99966824\n",
      "Loss (epoch: 3): 0.99956864\n",
      "Loss (epoch: 4): 0.9994061\n",
      "Loss (epoch: 5): 0.9990966\n",
      "0.01910282\n",
      "4.5251318e-06\n",
      "0.018281266\n",
      "2.7035924e-06\n",
      "0.017572485\n",
      "3.9154816e-05\n",
      "0.017047513\n",
      "3.3647208e-05\n",
      "0.016529616\n",
      "9.176122e-05\n",
      "Loss (epoch: 5): 0.016621377\n",
      "Loss (epoch: 1): 0.9866818\n",
      "Loss (epoch: 2): 0.96447617\n",
      "Loss (epoch: 3): 0.9353213\n",
      "Loss (epoch: 4): 0.90541035\n",
      "Loss (epoch: 5): 0.868264\n",
      "0.016132819\n",
      "0.008443095\n",
      "0.017380046\n",
      "0.0012017299\n",
      "0.016531985\n",
      "0.0007330259\n",
      "0.016422171\n",
      "0.00024117199\n",
      "0.015933106\n",
      "0.0002649629\n",
      "Loss (epoch: 5): 0.016198069\n",
      "Loss (epoch: 1): 0.9793153\n",
      "Loss (epoch: 2): 0.9485096\n",
      "Loss (epoch: 3): 0.9004863\n",
      "Loss (epoch: 4): 0.84127676\n",
      "Loss (epoch: 5): 0.7767701\n",
      "0.015654512\n",
      "0.028455516\n",
      "0.023069898\n",
      "0.0005863772\n",
      "0.019052489\n",
      "0.0015993587\n",
      "0.019579496\n",
      "2.8304024e-05\n",
      "0.017785965\n",
      "0.000526235\n",
      "Loss (epoch: 5): 0.018312199\n",
      "Loss (epoch: 1): 0.99426776\n",
      "Loss (epoch: 2): 0.9731839\n",
      "Loss (epoch: 3): 0.9114703\n",
      "Loss (epoch: 4): 0.81468475\n",
      "Loss (epoch: 5): 0.66859466\n",
      "0.017580388\n",
      "0.07208821\n",
      "0.037811868\n",
      "1.6754622e-05\n",
      "0.028833179\n",
      "0.0035596248\n",
      "0.033310894\n",
      "1.9206153e-08\n",
      "0.026306627\n",
      "0.0009903284\n",
      "Loss (epoch: 5): 0.027296957\n",
      "Loss (epoch: 1): 0.99995816\n",
      "Loss (epoch: 2): 0.99995327\n",
      "Loss (epoch: 3): 0.9999471\n",
      "Loss (epoch: 4): 0.99993944\n",
      "Loss (epoch: 5): 0.99992967\n",
      "0.027034283\n",
      "2.0273565e-07\n",
      "0.022482865\n",
      "0.0006255829\n",
      "0.02242172\n",
      "1.0254372e-06\n",
      "0.019574285\n",
      "0.00041913328\n",
      "0.019242322\n",
      "4.760062e-06\n",
      "Loss (epoch: 5): 0.019247083\n",
      "Loss (epoch: 1): 0.96697456\n",
      "Loss (epoch: 2): 0.8714751\n",
      "Loss (epoch: 3): 0.7109589\n",
      "Loss (epoch: 4): 0.53928995\n",
      "Loss (epoch: 5): 0.38863525\n",
      "0.017442798\n",
      "0.23311657\n",
      "0.1709208\n",
      "0.0\n",
      "0.057923544\n",
      "0.002083653\n",
      "0.06108828\n",
      "0.0\n",
      "0.031790525\n",
      "0.00028584135\n",
      "Loss (epoch: 5): 0.032076366\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.028715895\n",
      "0.0\n",
      "0.022033062\n",
      "0.00017416874\n",
      "0.020419708\n",
      "1.1436061e-06\n",
      "0.018291406\n",
      "0.00018719811\n",
      "0.01757546\n",
      "1.79156e-05\n",
      "Loss (epoch: 5): 0.017593374\n",
      "Loss (epoch: 1): 0.97632575\n",
      "Loss (epoch: 2): 0.88153446\n",
      "Loss (epoch: 3): 0.7202993\n",
      "Loss (epoch: 4): 0.5270374\n",
      "Loss (epoch: 5): 0.35931805\n",
      "0.016578358\n",
      "0.2718717\n",
      "0.18656497\n",
      "0.0\n",
      "0.041661374\n",
      "0.008518704\n",
      "0.048859365\n",
      "0.0\n",
      "0.028736891\n",
      "0.0005938154\n",
      "Loss (epoch: 5): 0.029330706\n",
      "Loss (epoch: 1): 0.9999982\n",
      "Loss (epoch: 2): 0.9999982\n",
      "Loss (epoch: 3): 0.9999981\n",
      "Loss (epoch: 4): 0.99999803\n",
      "Loss (epoch: 5): 0.99999803\n",
      "0.02658814\n",
      "2.1410784e-09\n",
      "0.021943906\n",
      "0.00025273484\n",
      "0.020755865\n",
      "3.7740992e-06\n",
      "0.01910127\n",
      "0.00024183726\n",
      "0.018522846\n",
      "3.1841922e-05\n",
      "Loss (epoch: 5): 0.018554688\n",
      "Loss (epoch: 1): 0.97387236\n",
      "Loss (epoch: 2): 0.8341334\n",
      "Loss (epoch: 3): 0.62543434\n",
      "Loss (epoch: 4): 0.43265882\n",
      "Loss (epoch: 5): 0.2787546\n",
      "0.017609578\n",
      "0.35261238\n",
      "0.26615605\n",
      "0.0\n",
      "0.035770927\n",
      "0.0044179317\n",
      "0.037007097\n",
      "0.0\n",
      "0.025974663\n",
      "0.00028623763\n",
      "Loss (epoch: 5): 0.026260901\n",
      "Loss (epoch: 1): 0.99988806\n",
      "Loss (epoch: 2): 0.9998451\n",
      "Loss (epoch: 3): 0.9997564\n",
      "Loss (epoch: 4): 0.9995422\n",
      "Loss (epoch: 5): 0.998787\n",
      "0.023925016\n",
      "3.6191712e-05\n",
      "0.021374539\n",
      "0.0008084192\n",
      "0.021101873\n",
      "3.080117e-05\n",
      "0.019738717\n",
      "0.00037206832\n",
      "0.019300941\n",
      "6.530927e-05\n",
      "Loss (epoch: 5): 0.019366251\n",
      "Loss (epoch: 1): 0.9712068\n",
      "Loss (epoch: 2): 0.8568702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss (epoch: 3): 0.68830967\n",
      "Loss (epoch: 4): 0.5325822\n",
      "Loss (epoch: 5): 0.3917774\n",
      "0.018432535\n",
      "0.2343869\n",
      "0.16976506\n",
      "0.0\n",
      "0.03770114\n",
      "0.0016297267\n",
      "0.035338305\n",
      "0.0\n",
      "0.025417557\n",
      "0.00014379247\n",
      "Loss (epoch: 5): 0.02556135\n",
      "Loss (epoch: 1): 0.99995214\n",
      "Loss (epoch: 2): 0.99993914\n",
      "Loss (epoch: 3): 0.99992126\n",
      "Loss (epoch: 4): 0.9998937\n",
      "Loss (epoch: 5): 0.9998411\n",
      "0.023102896\n",
      "6.752386e-07\n",
      "0.020746704\n",
      "0.00032068673\n",
      "0.02001419\n",
      "1.5030545e-05\n",
      "0.018827975\n",
      "0.000252318\n",
      "0.018318685\n",
      "4.9840535e-05\n",
      "Loss (epoch: 5): 0.018368525\n",
      "Loss (epoch: 1): 0.9750732\n",
      "Loss (epoch: 2): 0.8637835\n",
      "Loss (epoch: 3): 0.7105754\n",
      "Loss (epoch: 4): 0.54984003\n",
      "Loss (epoch: 5): 0.40586746\n",
      "0.017528793\n",
      "0.22609362\n",
      "0.15909384\n",
      "0.0\n",
      "0.03716685\n",
      "5.7691173e-06\n",
      "0.030000072\n",
      "0.0\n",
      "0.022663804\n",
      "1.6733515e-05\n",
      "Loss (epoch: 5): 0.022680538\n",
      "Loss (epoch: 1): 0.99996793\n",
      "Loss (epoch: 2): 0.99996346\n",
      "Loss (epoch: 3): 0.99995816\n",
      "Loss (epoch: 4): 0.99995136\n",
      "Loss (epoch: 5): 0.9999412\n",
      "0.02041536\n",
      "1.5260746e-07\n",
      "0.018750723\n",
      "0.00011097939\n",
      "0.017966293\n",
      "1.4643381e-05\n",
      "0.017101254\n",
      "0.00014978292\n",
      "0.016610995\n",
      "4.4489596e-05\n",
      "Loss (epoch: 5): 0.016655484\n",
      "Loss (epoch: 1): 0.98103845\n",
      "Loss (epoch: 2): 0.8910965\n",
      "Loss (epoch: 3): 0.76800406\n",
      "Loss (epoch: 4): 0.6275881\n",
      "Loss (epoch: 5): 0.47843406\n",
      "0.015991619\n",
      "0.18228619\n",
      "0.13038808\n",
      "0.0\n",
      "0.034356456\n",
      "0.0\n",
      "0.027339337\n",
      "0.0\n",
      "0.02077758\n",
      "0.0\n",
      "Loss (epoch: 5): 0.02077758\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.018634703\n",
      "0.0\n",
      "0.017199725\n",
      "2.7039406e-09\n",
      "0.016309213\n",
      "3.230006e-09\n",
      "0.01560906\n",
      "5.3846344e-07\n",
      "0.0150219295\n",
      "2.3389443e-06\n",
      "Loss (epoch: 5): 0.015024268\n",
      "Loss (epoch: 1): 0.9952006\n",
      "Loss (epoch: 2): 0.9553471\n",
      "Loss (epoch: 3): 0.84373945\n",
      "Loss (epoch: 4): 0.71832794\n",
      "Loss (epoch: 5): 0.56308883\n",
      "0.014501916\n",
      "0.12846582\n",
      "0.0772251\n",
      "0.0\n",
      "0.02873909\n",
      "0.0\n",
      "0.023156522\n",
      "0.0\n",
      "0.018410634\n",
      "0.0\n",
      "Loss (epoch: 5): 0.018410634\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.016759625\n",
      "0.0\n",
      "0.015663022\n",
      "0.0\n",
      "0.014959228\n",
      "0.0\n",
      "0.01439457\n",
      "0.0\n",
      "0.013909787\n",
      "1.8714677e-10\n",
      "Loss (epoch: 5): 0.013909787\n",
      "Loss (epoch: 1): 0.99999833\n",
      "Loss (epoch: 2): 0.99999833\n",
      "Loss (epoch: 3): 0.99999833\n",
      "Loss (epoch: 4): 0.99999833\n",
      "Loss (epoch: 5): 0.99999833\n",
      "0.0134714935\n",
      "6.99434e-09\n",
      "0.013067289\n",
      "2.6737103e-08\n",
      "0.012690553\n",
      "2.6397004e-07\n",
      "0.012337774\n",
      "1.4757481e-06\n",
      "0.012007197\n",
      "6.647587e-06\n",
      "Loss (epoch: 5): 0.012013845\n",
      "Loss (epoch: 1): 0.99567145\n",
      "Loss (epoch: 2): 0.96502596\n",
      "Loss (epoch: 3): 0.8512268\n",
      "Loss (epoch: 4): 0.7131514\n",
      "Loss (epoch: 5): 0.5672594\n",
      "0.011701607\n",
      "0.12176394\n",
      "0.06600507\n",
      "0.0\n",
      "0.023103585\n",
      "0.0\n",
      "0.01835981\n",
      "0.0\n",
      "0.015029956\n",
      "0.0\n",
      "Loss (epoch: 5): 0.015029956\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.013885025\n",
      "0.0\n",
      "0.013165788\n",
      "0.0\n",
      "0.012683925\n",
      "0.0\n",
      "0.012285259\n",
      "0.0\n",
      "0.011931717\n",
      "0.0\n",
      "Loss (epoch: 5): 0.011931717\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.011605993\n",
      "0.0\n",
      "0.011301474\n",
      "0.0\n",
      "0.011014706\n",
      "0.0\n",
      "0.010743568\n",
      "7.6146006e-10\n",
      "0.010486346\n",
      "5.2537166e-09\n",
      "Loss (epoch: 5): 0.010486351\n",
      "Loss (epoch: 1): 0.9999935\n",
      "Loss (epoch: 2): 0.9999935\n",
      "Loss (epoch: 3): 0.9999933\n",
      "Loss (epoch: 4): 0.99999315\n",
      "Loss (epoch: 5): 0.99999297\n",
      "0.010241931\n",
      "1.998626e-08\n",
      "0.010009144\n",
      "1.1090329e-07\n",
      "0.009787071\n",
      "4.842744e-07\n",
      "0.009575448\n",
      "1.7187893e-06\n",
      "0.009374129\n",
      "4.9147484e-06\n",
      "Loss (epoch: 5): 0.009379043\n",
      "Loss (epoch: 1): 0.997366\n",
      "Loss (epoch: 2): 0.9866722\n",
      "Loss (epoch: 3): 0.9280209\n",
      "Loss (epoch: 4): 0.84967184\n",
      "Loss (epoch: 5): 0.7500859\n",
      "0.009183951\n",
      "0.04241606\n",
      "0.023333874\n",
      "0.0\n",
      "0.012935266\n",
      "7.648177e-05\n",
      "0.011324816\n",
      "4.5835034e-07\n",
      "0.010341002\n",
      "3.8557104e-05\n",
      "Loss (epoch: 5): 0.010379558\n",
      "Loss (epoch: 1): 0.9968521\n",
      "Loss (epoch: 2): 0.9788\n",
      "Loss (epoch: 3): 0.8836238\n",
      "Loss (epoch: 4): 0.7798843\n",
      "Loss (epoch: 5): 0.65707564\n",
      "0.009985341\n",
      "0.07450125\n",
      "0.03592489\n",
      "0.0\n",
      "0.017121684\n",
      "7.091338e-05\n",
      "0.014303572\n",
      "5.0514206e-09\n",
      "0.0121647185\n",
      "2.82152e-05\n",
      "Loss (epoch: 5): 0.012192934\n",
      "Loss (epoch: 1): 0.9992025\n",
      "Loss (epoch: 2): 0.99653757\n",
      "Loss (epoch: 3): 0.9651654\n",
      "Loss (epoch: 4): 0.85971385\n",
      "Loss (epoch: 5): 0.72985154\n",
      "0.0114549035\n",
      "0.05045678\n",
      "0.027551154\n",
      "0.0\n",
      "0.017176645\n",
      "9.1868256e-05\n",
      "0.01511159\n",
      "8.252736e-10\n",
      "0.013123556\n",
      "4.2417567e-05\n",
      "Loss (epoch: 5): 0.013165974\n",
      "Loss (epoch: 1): 0.9995269\n",
      "Loss (epoch: 2): 0.9983028\n",
      "Loss (epoch: 3): 0.9829339\n",
      "Loss (epoch: 4): 0.88425916\n",
      "Loss (epoch: 5): 0.7653741\n",
      "0.012415341\n",
      "0.039422758\n",
      "0.025006384\n",
      "0.0\n",
      "0.017488865\n",
      "0.00022734418\n",
      "0.016133243\n",
      "7.9102663e-10\n",
      "0.014023867\n",
      "7.262477e-05\n",
      "Loss (epoch: 5): 0.014096492\n",
      "Loss (epoch: 1): 0.99964833\n",
      "Loss (epoch: 2): 0.9989233\n",
      "Loss (epoch: 3): 0.9918236\n",
      "Loss (epoch: 4): 0.90016055\n",
      "Loss (epoch: 5): 0.7403548\n",
      "0.013311374\n",
      "0.051569324\n",
      "0.03095428\n",
      "0.0\n",
      "0.020698389\n",
      "0.001101337\n",
      "0.02085673\n",
      "0.0\n",
      "0.016685268\n",
      "9.882409e-05\n",
      "Loss (epoch: 5): 0.016784092\n",
      "Loss (epoch: 1): 0.99998707\n",
      "Loss (epoch: 2): 0.9999861\n",
      "Loss (epoch: 3): 0.9999849\n",
      "Loss (epoch: 4): 0.9999834\n",
      "Loss (epoch: 5): 0.9999814\n",
      "0.015535224\n",
      "6.487377e-08\n",
      "0.0140908705\n",
      "0.00012634901\n",
      "0.01364035\n",
      "2.7078095e-06\n",
      "0.012924692\n",
      "0.0001361958\n",
      "0.012685819\n",
      "1.3522146e-05\n",
      "Loss (epoch: 5): 0.0126993405\n",
      "Loss (epoch: 1): 0.9816416\n",
      "Loss (epoch: 2): 0.8253771\n",
      "Loss (epoch: 3): 0.6602753\n",
      "Loss (epoch: 4): 0.52273244\n",
      "Loss (epoch: 5): 0.3951648\n",
      "0.012210765\n",
      "0.22105874\n",
      "0.16312934\n",
      "0.0\n",
      "0.044218875\n",
      "0.0\n",
      "0.035060015\n",
      "0.0\n",
      "0.020252239\n",
      "0.0\n",
      "Loss (epoch: 5): 0.020252239\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.017230261\n",
      "0.0\n",
      "0.015042255\n",
      "0.0\n",
      "0.014108439\n",
      "0.0\n",
      "0.013466827\n",
      "0.0\n",
      "0.013012588\n",
      "0.0\n",
      "Loss (epoch: 5): 0.013012588\n",
      "Loss (epoch: 1): 0.99999726\n",
      "Loss (epoch: 2): 0.99999726\n",
      "Loss (epoch: 3): 0.99999714\n",
      "Loss (epoch: 4): 0.99999714\n",
      "Loss (epoch: 5): 0.99999714\n",
      "0.012631594\n",
      "9.277096e-09\n",
      "0.01229333\n",
      "2.7628618e-08\n",
      "0.011981308\n",
      "3.7862694e-07\n",
      "0.0116895195\n",
      "2.19087e-06\n",
      "0.01141633\n",
      "1.1645495e-05\n",
      "Loss (epoch: 5): 0.011427975\n",
      "Loss (epoch: 1): 0.99369586\n",
      "Loss (epoch: 2): 0.9229137\n",
      "Loss (epoch: 3): 0.7820983\n",
      "Loss (epoch: 4): 0.6349775\n",
      "Loss (epoch: 5): 0.49353418\n",
      "0.011169907\n",
      "0.16551435\n",
      "0.10039863\n",
      "0.0\n",
      "0.02833369\n",
      "0.0\n",
      "0.022032667\n",
      "0.0\n",
      "0.01611647\n",
      "0.0\n",
      "Loss (epoch: 5): 0.01611647\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.014390312\n",
      "0.0\n",
      "0.013292246\n",
      "0.0\n",
      "0.012692108\n",
      "0.0\n",
      "0.012246647\n",
      "0.0\n",
      "0.011886291\n",
      "0.0\n",
      "Loss (epoch: 5): 0.011886291\n",
      "Loss (epoch: 1): 0.99999595\n",
      "Loss (epoch: 2): 0.99999577\n",
      "Loss (epoch: 3): 0.9999956\n",
      "Loss (epoch: 4): 0.9999953\n",
      "Loss (epoch: 5): 0.9999951\n",
      "0.011567533\n",
      "7.47904e-09\n",
      "0.011275963\n",
      "7.506259e-08\n",
      "0.011003903\n",
      "1.1052209e-06\n",
      "0.010749536\n",
      "5.476157e-06\n",
      "0.010514604\n",
      "1.792326e-05\n",
      "Loss (epoch: 5): 0.010532527\n",
      "Loss (epoch: 1): 0.9931924\n",
      "Loss (epoch: 2): 0.89235055\n",
      "Loss (epoch: 3): 0.7302402\n",
      "Loss (epoch: 4): 0.54700214\n",
      "Loss (epoch: 5): 0.36935067\n",
      "0.010305905\n",
      "0.27777156\n",
      "0.19093588\n",
      "0.0\n",
      "0.029822363\n",
      "0.0\n",
      "0.02197453\n",
      "0.0\n",
      "0.0154593745\n",
      "0.0\n",
      "Loss (epoch: 5): 0.0154593745\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.013811038\n",
      "0.0\n",
      "0.012867151\n",
      "0.0\n",
      "0.0123485355\n",
      "0.0\n",
      "0.011957086\n",
      "0.0\n",
      "0.011627858\n",
      "0.0\n",
      "Loss (epoch: 5): 0.011627858\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.011330213\n",
      "0.0\n",
      "0.011053802\n",
      "0.0\n",
      "0.010793702\n",
      "0.0\n",
      "0.010547352\n",
      "0.0\n",
      "0.010313251\n",
      "0.0\n",
      "Loss (epoch: 5): 0.010313251\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.010090283\n",
      "0.0\n",
      "0.009877351\n",
      "0.0\n",
      "0.009673508\n",
      "0.0\n",
      "0.0094780885\n",
      "0.0\n",
      "0.009290199\n",
      "0.0\n",
      "Loss (epoch: 5): 0.009290199\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.009109288\n",
      "0.0\n",
      "0.008935021\n",
      "0.0\n",
      "0.008767014\n",
      "0.0\n",
      "0.008604791\n",
      "0.0\n",
      "0.008448107\n",
      "0.0\n",
      "Loss (epoch: 5): 0.008448107\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.008296694\n",
      "0.0\n",
      "0.008150216\n",
      "1.9175678e-11\n",
      "0.008008444\n",
      "2.0139796e-09\n",
      "0.007871207\n",
      "1.3647361e-08\n",
      "0.0077382503\n",
      "4.9703008e-08\n",
      "Loss (epoch: 5): 0.0077383\n",
      "Loss (epoch: 1): 0.99993974\n",
      "Loss (epoch: 2): 0.9999279\n",
      "Loss (epoch: 3): 0.9999095\n",
      "Loss (epoch: 4): 0.999882\n",
      "Loss (epoch: 5): 0.99983716\n",
      "0.007609479\n",
      "7.251908e-07\n",
      "0.007485279\n",
      "1.8091986e-06\n",
      "0.0073657087\n",
      "3.943094e-06\n",
      "0.0072512114\n",
      "7.3948167e-06\n",
      "0.0071422225\n",
      "1.18850485e-05\n",
      "Loss (epoch: 5): 0.0071541076\n",
      "Loss (epoch: 1): 0.99623954\n",
      "Loss (epoch: 2): 0.96491325\n",
      "Loss (epoch: 3): 0.84342575\n",
      "Loss (epoch: 4): 0.7219196\n",
      "Loss (epoch: 5): 0.5768181\n",
      "0.007038876\n",
      "0.12529777\n",
      "0.06495714\n",
      "0.0\n",
      "0.014499092\n",
      "0.0\n",
      "0.010989739\n",
      "0.0\n",
      "0.009415109\n",
      "0.0\n",
      "Loss (epoch: 5): 0.009415109\n",
      "Loss (epoch: 1): 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.008905703\n",
      "0.0\n",
      "0.008608998\n",
      "0.0\n",
      "0.008388918\n",
      "0.0\n",
      "0.008197195\n",
      "0.0\n",
      "0.008021908\n",
      "0.0\n",
      "Loss (epoch: 5): 0.008021908\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.007858416\n",
      "0.0\n",
      "0.0077045653\n",
      "0.0\n",
      "0.0075584645\n",
      "0.0\n",
      "0.007419457\n",
      "0.0\n",
      "0.007286688\n",
      "2.6286565e-11\n",
      "Loss (epoch: 5): 0.007286688\n",
      "Loss (epoch: 1): 0.9999984\n",
      "Loss (epoch: 2): 0.9999984\n",
      "Loss (epoch: 3): 0.9999984\n",
      "Loss (epoch: 4): 0.9999984\n",
      "Loss (epoch: 5): 0.9999984\n",
      "0.0071595167\n",
      "2.0061082e-09\n",
      "0.007037376\n",
      "1.4283202e-08\n",
      "0.0069200024\n",
      "5.2267826e-08\n",
      "0.0068071303\n",
      "1.6539397e-07\n",
      "0.00669838\n",
      "4.887725e-07\n",
      "Loss (epoch: 5): 0.006698869\n",
      "Loss (epoch: 1): 0.9995486\n",
      "Loss (epoch: 2): 0.9986435\n",
      "Loss (epoch: 3): 0.98968667\n",
      "Loss (epoch: 4): 0.8992429\n",
      "Loss (epoch: 5): 0.7613771\n",
      "0.006593639\n",
      "0.05430279\n",
      "0.027616339\n",
      "0.0\n",
      "0.010891995\n",
      "1.4511514e-07\n",
      "0.008761557\n",
      "0.0\n",
      "0.0078806635\n",
      "7.286848e-08\n",
      "Loss (epoch: 5): 0.007880736\n",
      "Loss (epoch: 1): 0.9999843\n",
      "Loss (epoch: 2): 0.99998295\n",
      "Loss (epoch: 3): 0.99998134\n",
      "Loss (epoch: 4): 0.99997926\n",
      "Loss (epoch: 5): 0.9999765\n",
      "0.007562383\n",
      "5.4421733e-08\n",
      "0.0073643746\n",
      "9.854847e-07\n",
      "0.0072095944\n",
      "2.0977354e-06\n",
      "0.0070711044\n",
      "7.747109e-06\n",
      "0.006948425\n",
      "1.3462124e-05\n",
      "Loss (epoch: 5): 0.0069618872\n",
      "Loss (epoch: 1): 0.99449587\n",
      "Loss (epoch: 2): 0.9255382\n",
      "Loss (epoch: 3): 0.7764312\n",
      "Loss (epoch: 4): 0.5206923\n",
      "Loss (epoch: 5): 0.28350997\n",
      "0.0068352446\n",
      "0.3899124\n",
      "0.26134196\n",
      "0.0\n",
      "0.019985791\n",
      "0.0\n",
      "0.013887324\n",
      "0.0\n",
      "0.0108550945\n",
      "0.0\n",
      "Loss (epoch: 5): 0.0108550945\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.010038596\n",
      "0.0\n",
      "0.009591479\n",
      "0.0\n",
      "0.009280171\n",
      "0.0\n",
      "0.00901755\n",
      "0.0\n",
      "0.008782004\n",
      "0.0\n",
      "Loss (epoch: 5): 0.008782004\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.008565489\n",
      "0.0\n",
      "0.008364254\n",
      "0.0\n",
      "0.0081759095\n",
      "0.0\n",
      "0.007998608\n",
      "0.0\n",
      "0.007830989\n",
      "0.0\n",
      "Loss (epoch: 5): 0.007830989\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.0076721846\n",
      "0.0\n",
      "0.007521173\n",
      "0.0\n",
      "0.007377076\n",
      "0.0\n",
      "0.0072393566\n",
      "0.0\n",
      "0.007107388\n",
      "0.0\n",
      "Loss (epoch: 5): 0.007107388\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.0069807614\n",
      "0.0\n",
      "0.0068591167\n",
      "0.0\n",
      "0.0067420406\n",
      "0.0\n",
      "0.0066291564\n",
      "0.0\n",
      "0.0065202885\n",
      "0.0\n",
      "Loss (epoch: 5): 0.0065202885\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.006415041\n",
      "0.0\n",
      "0.006313198\n",
      "0.0\n",
      "0.0062146694\n",
      "0.0\n",
      "0.006119321\n",
      "0.0\n",
      "0.006026934\n",
      "7.861573e-10\n",
      "Loss (epoch: 5): 0.006026935\n",
      "Loss (epoch: 1): 0.99999315\n",
      "Loss (epoch: 2): 0.9999927\n",
      "Loss (epoch: 3): 0.99999243\n",
      "Loss (epoch: 4): 0.9999922\n",
      "Loss (epoch: 5): 0.9999919\n",
      "0.005937326\n",
      "1.1609983e-08\n",
      "0.005850457\n",
      "4.8517514e-08\n",
      "0.0057661724\n",
      "1.5479824e-07\n",
      "0.0056844493\n",
      "4.0637795e-07\n",
      "0.005605282\n",
      "9.3486307e-07\n",
      "Loss (epoch: 5): 0.005606217\n",
      "Loss (epoch: 1): 0.9993381\n",
      "Loss (epoch: 2): 0.99818045\n",
      "Loss (epoch: 3): 0.9889576\n",
      "Loss (epoch: 4): 0.9222988\n",
      "Loss (epoch: 5): 0.8251284\n",
      "0.005528723\n",
      "0.024276812\n",
      "0.01103422\n",
      "1.1662103e-05\n",
      "0.0067719053\n",
      "0.0005490245\n",
      "0.0065345136\n",
      "5.253929e-06\n",
      "0.0061364425\n",
      "4.8783528e-05\n",
      "Loss (epoch: 5): 0.006185226\n",
      "Loss (epoch: 1): 0.9954739\n",
      "Loss (epoch: 2): 0.94275767\n",
      "Loss (epoch: 3): 0.78596014\n",
      "Loss (epoch: 4): 0.5029275\n",
      "Loss (epoch: 5): 0.3097258\n",
      "0.0060333624\n",
      "0.32472065\n",
      "0.19496973\n",
      "0.0\n",
      "0.014101404\n",
      "0.0\n",
      "0.01089316\n",
      "0.0\n",
      "0.00951791\n",
      "0.0\n",
      "Loss (epoch: 5): 0.00951791\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.008982286\n",
      "0.0\n",
      "0.008629617\n",
      "0.0\n",
      "0.0083492845\n",
      "0.0\n",
      "0.008104604\n",
      "0.0\n",
      "0.007884512\n",
      "0.0\n",
      "Loss (epoch: 5): 0.007884512\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.007683269\n",
      "0.0\n",
      "0.00749783\n",
      "0.0\n",
      "0.0073255585\n",
      "0.0\n",
      "0.007164854\n",
      "0.0\n",
      "0.007014044\n",
      "0.0\n",
      "Loss (epoch: 5): 0.007014044\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.006871556\n",
      "0.0\n",
      "0.006736304\n",
      "0.0\n",
      "0.006607864\n",
      "0.0\n",
      "0.006485681\n",
      "0.0\n",
      "0.0063690864\n",
      "0.0\n",
      "Loss (epoch: 5): 0.0063690864\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.0062573967\n",
      "0.0\n",
      "0.006150325\n",
      "5.384712e-10\n",
      "0.0060475185\n",
      "5.602882e-09\n",
      "0.005948601\n",
      "3.315033e-08\n",
      "0.00585334\n",
      "1.3207834e-07\n",
      "Loss (epoch: 5): 0.0058534723\n",
      "Loss (epoch: 1): 0.9997917\n",
      "Loss (epoch: 2): 0.9996216\n",
      "Loss (epoch: 3): 0.99904764\n",
      "Loss (epoch: 4): 0.9951818\n",
      "Loss (epoch: 5): 0.9567203\n",
      "0.005761699\n",
      "0.0057752253\n",
      "0.007230043\n",
      "9.344199e-06\n",
      "0.006179504\n",
      "0.00015224917\n",
      "0.0060636504\n",
      "1.3917165e-05\n",
      "0.0058972295\n",
      "4.0274284e-05\n",
      "Loss (epoch: 5): 0.0059375037\n",
      "Loss (epoch: 1): 0.9941301\n",
      "Loss (epoch: 2): 0.9300207\n",
      "Loss (epoch: 3): 0.72450703\n",
      "Loss (epoch: 4): 0.49852988\n",
      "Loss (epoch: 5): 0.32238123\n",
      "0.0058235456\n",
      "0.30841294\n",
      "0.19572575\n",
      "0.0\n",
      "0.015287176\n",
      "0.0\n",
      "0.011410026\n",
      "0.0\n",
      "0.009703772\n",
      "0.0\n",
      "Loss (epoch: 5): 0.009703772\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.009068017\n",
      "0.0\n",
      "0.008659035\n",
      "0.0\n",
      "0.0083405925\n",
      "0.0\n",
      "0.008066617\n",
      "0.0\n",
      "0.0078229075\n",
      "0.0\n",
      "Loss (epoch: 5): 0.0078229075\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.0076026227\n",
      "0.0\n",
      "0.0074015562\n",
      "0.0\n",
      "0.0072164014\n",
      "0.0\n",
      "0.0070446683\n",
      "0.0\n",
      "0.006884526\n",
      "0.0\n",
      "Loss (epoch: 5): 0.006884526\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.006734387\n",
      "0.0\n",
      "0.0065930183\n",
      "1.141252e-11\n",
      "0.006459404\n",
      "1.5042564e-09\n",
      "0.0063327383\n",
      "1.4378957e-08\n",
      "0.006212351\n",
      "6.4543826e-08\n",
      "Loss (epoch: 5): 0.0062124156\n",
      "Loss (epoch: 1): 0.9999318\n",
      "Loss (epoch: 2): 0.9999155\n",
      "Loss (epoch: 3): 0.9998928\n",
      "Loss (epoch: 4): 0.99985605\n",
      "Loss (epoch: 5): 0.99978983\n",
      "0.006097902\n",
      "1.1637037e-06\n",
      "0.005989566\n",
      "2.5861575e-06\n",
      "0.005886892\n",
      "5.1397683e-06\n",
      "0.005790255\n",
      "8.97745e-06\n",
      "0.0056997053\n",
      "1.3792764e-05\n",
      "Loss (epoch: 5): 0.005713498\n",
      "Loss (epoch: 1): 0.9959494\n",
      "Loss (epoch: 2): 0.95940137\n",
      "Loss (epoch: 3): 0.78962165\n",
      "Loss (epoch: 4): 0.5758656\n",
      "Loss (epoch: 5): 0.4002824\n",
      "0.005615203\n",
      "0.24040782\n",
      "0.14700986\n",
      "0.0\n",
      "0.014253101\n",
      "0.0\n",
      "0.010803296\n",
      "0.0\n",
      "0.009361243\n",
      "0.0\n",
      "Loss (epoch: 5): 0.009361243\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.00877547\n",
      "0.0\n",
      "0.008378835\n",
      "4.423361e-11\n",
      "0.008060745\n",
      "5.8236576e-09\n",
      "0.0077857426\n",
      "8.0101294e-08\n",
      "0.007541432\n",
      "3.548752e-07\n",
      "Loss (epoch: 5): 0.007541787\n",
      "Loss (epoch: 1): 0.99958384\n",
      "Loss (epoch: 2): 0.99898064\n",
      "Loss (epoch: 3): 0.995172\n",
      "Loss (epoch: 4): 0.95004725\n",
      "Loss (epoch: 5): 0.80725175\n",
      "0.007321414\n",
      "0.043793608\n",
      "0.026495038\n",
      "0.0\n",
      "0.011548203\n",
      "0.00017185717\n",
      "0.009875209\n",
      "2.821026e-07\n",
      "0.008751626\n",
      "5.7580197e-05\n",
      "Loss (epoch: 5): 0.008809206\n",
      "Loss (epoch: 1): 0.9956812\n",
      "Loss (epoch: 2): 0.9434076\n",
      "Loss (epoch: 3): 0.7733363\n",
      "Loss (epoch: 4): 0.5095083\n",
      "Loss (epoch: 5): 0.29852602\n",
      "0.008379509\n",
      "0.3416528\n",
      "0.2598292\n",
      "0.0\n",
      "0.027507635\n",
      "4.113902e-09\n",
      "0.018176215\n",
      "0.0\n",
      "0.013270962\n",
      "0.0\n",
      "Loss (epoch: 5): 0.013270962\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.011920045\n",
      "0.0\n",
      "0.011132958\n",
      "2.6008166e-08\n",
      "0.010568286\n",
      "1.6508145e-07\n",
      "0.010100453\n",
      "3.6253482e-06\n",
      "0.009701876\n",
      "1.5290043e-05\n",
      "Loss (epoch: 5): 0.009717166\n",
      "Loss (epoch: 1): 0.9911823\n",
      "Loss (epoch: 2): 0.89772207\n",
      "Loss (epoch: 3): 0.7533721\n",
      "Loss (epoch: 4): 0.5737921\n",
      "Loss (epoch: 5): 0.3962365\n",
      "0.009363992\n",
      "0.24695763\n",
      "0.1804459\n",
      "0.0\n",
      "0.01960294\n",
      "0.0\n",
      "0.014916531\n",
      "0.0\n",
      "0.012728337\n",
      "0.0\n",
      "Loss (epoch: 5): 0.012728337\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.011834914\n",
      "0.0\n",
      "0.011222549\n",
      "0.0\n",
      "0.0107314745\n",
      "1.1211522e-10\n",
      "0.010306742\n",
      "6.318261e-08\n",
      "0.00992993\n",
      "8.4348227e-07\n",
      "Loss (epoch: 5): 0.009930774\n",
      "Loss (epoch: 1): 0.9972232\n",
      "Loss (epoch: 2): 0.9525935\n",
      "Loss (epoch: 3): 0.7932319\n",
      "Loss (epoch: 4): 0.5495861\n",
      "Loss (epoch: 5): 0.35069236\n",
      "0.00959203\n",
      "0.29528025\n",
      "0.21245852\n",
      "0.0\n",
      "0.02137825\n",
      "0.0\n",
      "0.015899096\n",
      "0.0\n",
      "0.013271624\n",
      "0.0\n",
      "Loss (epoch: 5): 0.013271624\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.012279168\n",
      "0.0\n",
      "0.01162389\n",
      "0.0\n",
      "0.011111211\n",
      "0.0\n",
      "0.0106708985\n",
      "7.345389e-09\n",
      "0.010281257\n",
      "4.1243973e-07\n",
      "Loss (epoch: 5): 0.01028167\n",
      "Loss (epoch: 1): 0.99659353\n",
      "Loss (epoch: 2): 0.93926275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss (epoch: 3): 0.81668365\n",
      "Loss (epoch: 4): 0.65630037\n",
      "Loss (epoch: 5): 0.4670323\n",
      "0.009932954\n",
      "0.20102262\n",
      "0.1443834\n",
      "0.0\n",
      "0.019635702\n",
      "0.0\n",
      "0.014869418\n",
      "0.0\n",
      "0.012674366\n",
      "0.0\n",
      "Loss (epoch: 5): 0.012674366\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.011845868\n",
      "0.0\n",
      "0.011293036\n",
      "0.0\n",
      "0.01085202\n",
      "0.0\n",
      "0.010467064\n",
      "0.0\n",
      "0.010120243\n",
      "0.0\n",
      "Loss (epoch: 5): 0.010120243\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n",
      "0.009804405\n",
      "0.0\n",
      "0.009515055\n",
      "0.0\n",
      "0.009247092\n",
      "0.0\n",
      "0.0089976955\n",
      "0.0\n",
      "0.008765222\n",
      "0.0\n",
      "Loss (epoch: 5): 0.008765222\n",
      "Loss (epoch: 1): 1.0\n",
      "Loss (epoch: 2): 1.0\n",
      "Loss (epoch: 3): 1.0\n",
      "Loss (epoch: 4): 1.0\n",
      "Loss (epoch: 5): 1.0\n"
     ]
    }
   ],
   "source": [
    "no_of_training_loop = 100\n",
    "for i in range(no_of_training_loop):\n",
    "    Discriminator_training_model()\n",
    "    GAN_training_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fake = GAN_Model_WIP(fake_input_tensor.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_out = (input_fake[456]).reshape(28, 28).cpu().detach().numpy()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "#img=mpimg.imread('your_image.png')\n",
    "imgplot = plt.imshow(image_out)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6519e-03,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 5.8024e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.3991e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4463e-02,\n",
       "        0.0000e+00, 2.3693e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        6.8964e-03, 0.0000e+00, 0.0000e+00, 3.6550e-01, 0.0000e+00, 1.7755e-02,\n",
       "        0.0000e+00, 3.7543e-01, 0.0000e+00, 0.0000e+00, 1.0400e-01, 0.0000e+00,\n",
       "        2.7088e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4287e-02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3631e-02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7255e-02, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2100e-01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.8561e-02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5047e-02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 2.2692e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.9331e-01, 1.0606e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4794e-01,\n",
       "        5.5994e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.2008e-02,\n",
       "        0.0000e+00, 0.0000e+00, 1.2727e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0576e-02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6203e-01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.1401e-02, 0.0000e+00, 0.0000e+00, 6.0778e-01, 0.0000e+00,\n",
       "        0.0000e+00, 3.6026e-02, 0.0000e+00, 1.7266e-02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3643e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8720e-01, 0.0000e+00, 1.5372e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4391e-01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 3.7694e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 2.9902e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        7.9197e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1576e-01, 0.0000e+00,\n",
       "        0.0000e+00, 6.3942e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        8.5315e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8363e-02,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2295e-03,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3870e-01, 4.0879e-01, 0.0000e+00,\n",
       "        3.2831e-01, 9.7039e-01, 0.0000e+00, 2.7338e-01, 0.0000e+00, 2.7094e+00,\n",
       "        2.0404e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.6338e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 2.1163e-01, 0.0000e+00, 1.0804e-01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2658e-02, 0.0000e+00, 0.0000e+00,\n",
       "        1.9653e-01, 2.4934e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.4450e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8862e-02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.3550e-02, 0.0000e+00,\n",
       "        0.0000e+00, 4.9713e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0053e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.8441e-01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 3.1698e-01, 5.4404e-02, 0.0000e+00, 5.5316e-02, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9940e-01, 0.0000e+00,\n",
       "        0.0000e+00, 7.2295e-01, 0.0000e+00, 1.5052e-01, 5.6633e-01, 0.0000e+00,\n",
       "        4.7236e-01, 0.0000e+00, 0.0000e+00, 2.7425e-01, 0.0000e+00, 1.7184e-01,\n",
       "        0.0000e+00, 8.5989e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 2.2624e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.2002e-01, 0.0000e+00, 3.4253e-01,\n",
       "        5.7764e-01, 4.1071e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5501e-01,\n",
       "        5.4463e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1384e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6075e-02, 0.0000e+00,\n",
       "        4.5936e-01, 0.0000e+00, 2.7802e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        7.3697e-01, 6.9127e-01, 5.1926e-02, 0.0000e+00, 0.0000e+00, 7.7485e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6290e-03,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 8.0780e-02, 2.5696e-02, 0.0000e+00, 0.0000e+00, 8.1802e-01,\n",
       "        7.4784e-01, 5.2859e-01, 0.0000e+00, 4.9277e-01, 0.0000e+00, 1.7741e+00,\n",
       "        6.3198e-01, 3.7340e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 5.8871e-03, 0.0000e+00, 0.0000e+00, 7.9382e-03,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7410e-01, 0.0000e+00, 1.9758e-01,\n",
       "        0.0000e+00, 0.0000e+00, 6.3295e-01, 0.0000e+00, 2.5997e-01, 1.7759e-01,\n",
       "        0.0000e+00, 2.5927e-01, 0.0000e+00, 1.1237e+00, 1.3773e-01, 6.0796e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.9934e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        4.4709e-01, 0.0000e+00, 0.0000e+00, 5.4186e-01, 2.9456e-01, 1.4275e+00,\n",
       "        0.0000e+00, 1.6042e+00, 0.0000e+00, 0.0000e+00, 9.0510e-01, 0.0000e+00,\n",
       "        0.0000e+00, 2.6512e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5324e-01, 0.0000e+00,\n",
       "        1.6397e-01, 0.0000e+00, 1.2742e+00, 0.0000e+00, 1.0704e+00, 9.9315e-01,\n",
       "        0.0000e+00, 0.0000e+00, 4.2767e-01, 2.4131e-01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9108e-02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.5892e-01, 0.0000e+00, 6.4218e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.2341e+00, 9.3552e-01, 0.0000e+00, 0.0000e+00, 2.5784e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0053e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.3192e+00, 0.0000e+00, 0.0000e+00, 2.8790e-01, 0.0000e+00, 1.1002e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9021e-01, 1.0861e-01,\n",
       "        0.0000e+00, 1.4783e-01, 0.0000e+00, 1.2799e-01, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.5990e-01, 0.0000e+00, 0.0000e+00,\n",
       "        7.6035e-01, 2.0079e-01, 0.0000e+00, 0.0000e+00, 1.1470e+00, 0.0000e+00,\n",
       "        1.0719e+00, 7.0799e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7529e-03,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4823e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 4.1569e-02, 1.1026e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3755e-01, 7.8727e-03, 0.0000e+00,\n",
       "        0.0000e+00, 4.3092e-01, 7.2294e-01, 0.0000e+00, 1.4835e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6126e-01,\n",
       "        0.0000e+00, 5.2768e-02, 1.3535e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.1697e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8195e-01,\n",
       "        1.2324e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2091e-01,\n",
       "        0.0000e+00, 0.0000e+00, 3.6982e-01, 3.5161e-02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        2.0295e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7603e-02,\n",
       "        0.0000e+00, 0.0000e+00, 3.6968e-01, 0.0000e+00, 0.0000e+00, 1.9539e-01,\n",
       "        0.0000e+00, 1.5078e-01, 0.0000e+00, 0.0000e+00, 5.8152e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.6302e-03, 0.0000e+00, 0.0000e+00, 5.7680e-02, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.3658e-02, 0.0000e+00, 1.8163e-01, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1432e-01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 7.9001e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(input_fake[1] ==input_fake[220])\n",
    "input_fake[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
